{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./src')\n",
    "from models import EmbeddingModel\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckd cohort contains ICD code for subject and admission\n",
    "\n",
    "# N181: Chronic kidney disease, stage 1\n",
    "# N182: Chronic kidney disease, stage 2 (mild)\n",
    "# N183: Chronic kidney disease, stage 3 (moderate)\n",
    "# N184: Chronic kidney disease, stage 4 (severe)\n",
    "# N185: Chronic kidney disease, stage 5\n",
    "# N186: End stage renal disease\n",
    "# N189: Chronic kidney disease, unspecified\n",
    "\n",
    "# egfr categories: \n",
    "# 0 Unknown\n",
    "# 1 Normal or high \n",
    "# 2 Mildly decreased\n",
    "# 3 Moderately decreased\n",
    "# 4 Severely decreased\n",
    "# 5 Kidney failure\n",
    "\n",
    "filename = \"ckd_cohort10k\"\n",
    "cohort = pd.read_csv(f\"../eval_datasets/{filename}.csv\")\n",
    "data = pd.concat([\n",
    "        pd.read_csv(\"../data/note/discharge.csv\"),\n",
    "        pd.read_csv(\"../data/note/radiology.csv\")\n",
    "    ])\n",
    "print(cohort['icd_code'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'simcse'\n",
    "model = EmbeddingModel(model_name='../models/med_gte_simcse', pooling='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional preprocessing for ckd cohort \n",
    "def clean_text(text):\n",
    "    # Text Cleaning\n",
    "    text = re.sub(r'[_]+', '', text)    # Remove deidentifiers \n",
    "    text = text.replace('//', ' ')    # Replace // symbol with a space\n",
    "    text = re.sub(r'\\n+', ' ', text)    # Replace multiple newlines with a space\n",
    "    text = re.sub(r'\\s\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    \n",
    "    # Remove leading and trailing spaces\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def get_matching_texts(row, data):\n",
    "    matching_texts = data[(data['subject_id'] == row['subject_id']) & \n",
    "                          (data['hadm_id'] == row['hadm_id'])]['text'].tolist()\n",
    "    return [clean_text(text) for text in matching_texts if isinstance(text, str) and text.strip()]\n",
    "\n",
    "cohort['texts'] = cohort.apply(lambda row: get_matching_texts(row, data), axis=1)\n",
    "\n",
    "def chunk_text(text, max_tokens=512):\n",
    "    tokens = model.tokenizer.encode(text, add_special_tokens=False)\n",
    "    return [model.tokenizer.decode(tokens[i:i+max_tokens]) for i in range(0, len(tokens), max_tokens)]\n",
    "\n",
    "def process_row(row):\n",
    "    all_chunks = [chunk for text in row['texts'] for chunk in chunk_text(text)]\n",
    "    #embeddings = model.get_embedding(all_chunks)   \n",
    "    embeddings = []\n",
    "    \n",
    "    for chunk in all_chunks:\n",
    "        chunk_embedding = model.get_embedding([chunk])  # Pass a single chunk as a list\n",
    "        embeddings.append(chunk_embedding)\n",
    "    \n",
    "    # Concatenate all embeddings\n",
    "    embeddings = np.concatenate(embeddings, axis=0)\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "cohort['embedding'] = cohort.progress_apply(process_row, axis=1)\n",
    "\n",
    "print(f\"\\nNumber of rows in processed cohort: {len(cohort)}\")\n",
    "print(f\"Number of unique ICD codes: {cohort['icd_code'].nunique()}\")\n",
    "print(f\"Average number of texts per row: {cohort['texts'].apply(len).mean():.2f}\")\n",
    "\n",
    "print(cohort['icd_code'].value_counts())\n",
    "print(cohort['egfr_category'].value_counts())\n",
    "\n",
    "embeddings = np.stack(cohort['embedding'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings\n",
    "fp = f'../data/embeddings/{modelname}_{filename}.npy'\n",
    "np.save(fp, embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
